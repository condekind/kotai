{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from pprint import pprint\n",
    "\n",
    "# External\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory with the '.c' files and '.d' dirs\n",
    "benchmarkDir = '../tmp/seed_fns'\n",
    "\n",
    "# Patterns to look for in desired files\n",
    "patterns = {}\n",
    "patterns['case0_O1'] = '*.d/*_case0_O1.info'\n",
    "patterns['case0_Oz'] = '*.d/*_case0_Oz.info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoFilePaths = {progGroup: list(Path(benchmarkDir).glob(pattern)) for progGroup, pattern in patterns.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runInParallel = True  # Run in parallel?\n",
    "\n",
    "# Number of cpu cores (remove the `// 2` to use all the cores)\n",
    "nproc = len(os.sched_getaffinity(0)) // 2 if runInParallel else 1\n",
    "print(f'Using {nproc} core(s)')\n",
    "\n",
    "chunksize = 512\n",
    "print(f'Each cpu core will work on chunks of {chunksize} tasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads .info files faster if you have parallel disk access\n",
    "def parseInfo(infoFilePath):\n",
    "    try:\n",
    "        with open(infoFilePath, 'r') as infoFileHandle:\n",
    "            try:\n",
    "                info = yaml.safe_load(infoFileHandle)\n",
    "            except Exception as e:\n",
    "                print(f'{e}')\n",
    "                return None\n",
    "            else:\n",
    "                return info\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f'{e}')\n",
    "        return None\n",
    "\n",
    "# Turns each key in the inner dicts 'static' and 'dynamic' into a key in the\n",
    "# outer dict, e.g., accessing infoFile['static']['instructions'] becomes\n",
    "# infoFile['static_instructions']. This also makes pandas happier.\n",
    "def flattenCfgInfo(cfgInfo):\n",
    "    return {\n",
    "        'cfg': cfgInfo['cfg'],\n",
    "        'invoked': cfgInfo['invoked'],\n",
    "        'complete': cfgInfo['complete'],\n",
    "        'blocks': cfgInfo['blocks'],\n",
    "        'phantoms': cfgInfo['phantoms'],\n",
    "        'exit': cfgInfo['exit'],\n",
    "        'halt': cfgInfo['halt'],\n",
    "        'edges': cfgInfo['edges'],\n",
    "        'static_instructions': cfgInfo['static']['instructions'],\n",
    "        'static_calls': cfgInfo['static']['calls'],\n",
    "        'static_signals': cfgInfo['static']['signals'],\n",
    "        'dynamic_instructions': cfgInfo['dynamic']['instructions'],\n",
    "        'dynamic_calls': cfgInfo['dynamic']['calls'],\n",
    "        'dynamic_signals': cfgInfo['dynamic']['signals'],\n",
    "        'name': cfgInfo['name'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desiredCols = ['name', 'static_instructions', 'dynamic_instructions']\n",
    "\n",
    "print('The desired columns to be included in the dataframe are:')\n",
    "pd.DataFrame([], columns=desiredCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "infoGroups = {}\n",
    "with Pool(nproc) as pool:\n",
    "    for group, files in infoFilePaths.items():\n",
    "        res = pool.imap_unordered(parseInfo, files, chunksize)\n",
    "        infoGroups[group] = [flattenCfgInfo(r[0]) for r in res if r]\n",
    "        df[group] = pd.DataFrame(infoGroups[group], columns=desiredCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the path leading to the last prefix directory exists\n",
    "outputPrefix = 'output/cfgInfo'\n",
    "\n",
    "# Warning: [ , . ; : ] are all allowed characters for linux files\n",
    "csvSeparator = ';'\n",
    "\n",
    "for group in patterns.keys():\n",
    "    try:\n",
    "        df[group].to_csv(Path(outputPrefix + f'_{group}.csv'), sep=csvSeparator, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        print(f'{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in patterns.keys():\n",
    "    print(f'{group}:')\n",
    "    display(df[group].head())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kotai_3.10.0",
   "language": "python",
   "name": "kotai_3.10.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
