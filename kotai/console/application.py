#!/usr/bin/env python3
# =========================================================================== #

import argparse
import logging
from pathlib import Path
from multiprocessing import Pool
from typing import Counter

from kotai.constraints.genkonstrain import Konstrain
from kotai.plugin.PrintDescriptors import PrintDescriptors
from kotai.plugin.Jotai import Jotai
from kotai.plugin.Clang import Clang
from kotai.plugin.CFGgrind import CFGgrind
from kotai.templates.benchmark import GenBenchTemplatePrefix
from kotai.kotypes import BenchInfo, Failure, ExitCode, LogThen, OptLevel, OptLevels, SysExitCode, KonstrainExecType, KonstrainExecTypes, setLog, success, failure, valid
from kotai.logconf import logFmt, sep


# --------------------------------------------------------------------------- #
'''
TODOs:
    - Add checks to avoid re-running intermediate steps (check if files exist)

    - Modify Jotai.cpp to generate the new switch-based main from the prototype

    - Find a way to prepend the orig. function with __attribute__((noinline))

    - Find out which CFGgrind call creates "vgcore.XXXXXX" (temp) files and
      remove these files when they're no longer needed (or create them
      somewhere else)

    - Change wrappers so they don't need to be instantiated inside the worker
      functions. Maybe remove individual file attributes and make their methods
      static, receiving these attrs as args?
'''
# --------------------------------------------------------------------------- #

class Application:

    # maxtasksperchild (passed to mp.Pool ctor)
    mtpc: int = 16

    def __init__(self, ) -> None:

        # Attribute type annotation
        self.clean: bool
        self.inputdir: list[str]
        self.nproc: int
        self.chunksize: int
        self.optLevels: list[OptLevel] = []
        self.ketList: list[KonstrainExecType] = []
        self.logfile: str
        self.ubstats: str

        self.args = argparse.Namespace()
        cli = argparse.ArgumentParser(
            prog='python -m kotai',
            description='Jotai options'
        )

        cli.add_argument('-c', '--clean',     action='store_true', default=False)
        cli.add_argument('--no-log',          action='store_true', default=False)
        cli.add_argument('-i', '--inputdir',  type=str, nargs='+', required=True)
        cli.add_argument('-j', '--nproc',     type=int, default=8)
        cli.add_argument('-J', '--chunksize', type=int, default=-1)
        cli.add_argument('-K',         type=str, nargs='+', choices=KonstrainExecTypes, default='big-arr')
        cli.add_argument('--optLevel', type=str, nargs='+', choices=OptLevels,          default='O0')
        cli.add_argument('-L', '--logfile', default='./output/jotai.log')
        cli.add_argument('-u', '--ubstats', default='./output/ubstats.txt')
        cli.parse_args(namespace=self.args)

        # [-i]
        self.inputBenchmarks = [P for p in self.args.inputdir
                                  if (P := Path(p)).exists()]

        # [-j]
        self.nproc      = (self.args.nproc if self.args.nproc > 1
                           else 1)

        # [-J]
        self.chunksize  = (self.args.chunksize if self.args.chunksize > 1
                           else 64)

        # [-K]
        if 'all' in self.args.K:
            self.ketList = KonstrainExecTypes
        else:
            self.ketList = (kets if (kets := [ket for ket in self.args.K if ket in KonstrainExecTypes])
                              else ['big-arr'])

        # [--optLevel]
        if 'all' in self.args.optLevel:
            self.optLevels = list(OptLevels)
        else:
            self.optLevels = (opts if (opts := [opt for opt in self.args.optLevel if opt in OptLevels])
                              else ['O0'])

        self.ubstats = self.args.ubstats

        if self.args.no_log:
            # [--no-log] Disable logging
            logger = logging.getLogger()
            logger.propagate = False
            logger.disabled = True
            setLog(False)
        else:
            # [-L] Logging defaults
            setLog(True)
            logging.basicConfig(
                filename=self.args.logfile,
                filemode='w+',
                format=logFmt,
                level=logging.DEBUG
            )
            logging.debug(f'{self.args=}')


    def start(self, ) -> SysExitCode:
        return _start(self)  # Defined at the end of this file

# --------------------------------------------------------------------------- #


# Deletes the files generated by this program on a previous run
def _cleanFn(pArgs: BenchInfo) -> ExitCode:
    cFileMetaDir = pArgs.cFilePath.with_suffix('.d')
    genFiles     = cFileMetaDir.glob('*')

    # For each file inside the bench.d folder
    for file in genFiles:

        # Delete it
        try: file.unlink(missing_ok=True)
        except Exception as e:
            logging.error(f'{e}: {file}')
            continue

    # Finally, delete the .d folder
    try: cFileMetaDir.rmdir()
    except Exception as e:
        return LogThen.Err(f'{e}: {cFileMetaDir}')

    return LogThen.Ok(f'Deleted {cFileMetaDir}')


def getFnName(descriptor: str) -> str | Failure:
    '''
    Called by _genDescriptor to retrieve the fn name found in the benchmark.
    The name is important because we gather stats later with:
    $ cfggrind_info -f "benchBinPath::fnName" -s functions ...
    '''

    tokens = [t for t in descriptor.split() if t]

    if 'no-params' in tokens:        return failure
    if tokens.count('function') > 1: return failure

    # The fn name is the token after the 'function' keyword
    # The -1 excludes the last token, to avoid IndexError when we +1
    try: fn = '' + tokens[tokens.index('function', 0, -1) + 1]
    except Exception:                return failure
    else:                            return fn


# Worker function mapped in a multiprocessing.Pool to run PrintDescriptors
def _genDescriptor(pArgs: BenchInfo) -> BenchInfo:

    cFilePath = pArgs.cFilePath

    msg, err = PrintDescriptors(cFilePath).runcmd()

    # If the PrintDescriptors plugin fails, return before creating the file
    if err == failure:
        return pArgs.Err(f'PrintDescriptors [{cFilePath}]:"{msg=}"')

    # If the fnName isn't found, return before creating the file
    if (fnName := getFnName(msg)) == failure:
        return pArgs.Err(f'{fnName=}')

    # Creates the output dir for the current cFile
    cFileMetaDir = cFilePath.with_suffix('.d')
    try: cFileMetaDir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        return pArgs.Err(f'{e}: PrintDescriptors [{cFileMetaDir}]')

    # Creates the descriptor file
    descriptorPath = cFileMetaDir / 'descriptor'
    try:
        with open(descriptorPath, 'w', encoding='utf-8') as descFile:
            descFile.write(msg)
    except Exception as e:
        return pArgs.Err(f'{e}: PrintDescriptors [{descriptorPath}]')

    return BenchInfo(cFilePath, fnName)


# Worker function mapped in a multiprocessing.Pool to run Konstrain
def _runKonstrain(pArgs: BenchInfo) -> BenchInfo:
    cFilePath              = pArgs.cFilePath
    ket: KonstrainExecType = pArgs.ket
    cFileMetaDir           = cFilePath.with_suffix('.d')
    descriptorPath         = cFileMetaDir / 'descriptor'
    constraintsPath        = cFileMetaDir / f'constraint_{ket}'

    msg, err = Konstrain(descriptorPath, ket, constraintsPath).runcmd()

    if err == failure:
        return pArgs.Err(f'Konstrain [{cFilePath}]:"{msg=}"')

    return pArgs


# Worker function mapped in a multiprocessing.Pool to run Jotai
def _runJotai(pArgs: BenchInfo) -> BenchInfo:
    '''
    Creates genBenchFile: a main() entry point to the original benchmark.

    Individual sections of the result are added to a buffer, which is only
    stored to disk (genBenchFile) if every step was successful.

    The headers, defines and typedefs are added to the buffer, then Jotai is
    used to generate the mainFn body (as a string), which declares and
    initializes variables needed by the benchFn.
    '''

    cFilePath              = pArgs.cFilePath
    ket: KonstrainExecType = pArgs.ket

    # buffer <- includes, defines, typedefs and runtime info placeholder
    genBuffer = GenBenchTemplatePrefix

    # buffer += original benchmark function
    try:
        with open(cFilePath, 'r', encoding='utf-8') as cFileHandle:
            genBuffer += cFileHandle.read()
            genBuffer += f'\n\n\n{sep}\n\n'
    except Exception as e:
        return pArgs.Err(f'{e}')

    cFileMetaDir    = cFilePath.with_suffix('.d')
    descriptorPath  = cFileMetaDir / 'descriptor'
    constraintsPath = cFileMetaDir / f'constraint_{ket}'

    # Jotai's result
    mainFn, err     = Jotai(constraintsPath, descriptorPath).runcmd()

    # If error: returns before creating the genbench file
    if err == failure:
        return pArgs.Err(f'Jotai:\n{mainFn}\n')

    # buffer += mainFn body from successful Jotai run
    genBuffer += mainFn

    # Creates the genBench file and writes the buffer to it
    genBenchPath = cFileMetaDir / f'{cFilePath.stem}_{ket}.c'
    try:
        with open(genBenchPath, 'w', encoding='utf-8') as genBenchFile:
            try: genBenchFile.write(genBuffer)
            except Exception as e:
                return pArgs.Err(f'{e}')

    except Exception as e:
        return pArgs.Err(f'{e}')

    return pArgs


def _compileGenBench(pArgs: BenchInfo) -> BenchInfo:
    cFilePath    = pArgs.cFilePath
    ket          = pArgs.ket
    optLevel     = pArgs.optLevel
    cFileMetaDir = cFilePath.with_suffix('.d')
    genBenchPath = cFileMetaDir / f'{cFilePath.stem}_{ket}.c'
    genBinPath   = cFileMetaDir / f'{cFilePath.stem}_{ket}_{optLevel}'

    # Compiles the genBench into a binary
    _, err = Clang(optLevel, ofile=genBinPath, ifile=genBenchPath).runcmd()

    return (pArgs if err != failure
            else pArgs.Err())


def _runCFGgrind(pArgs: BenchInfo) -> BenchInfo:
    cFilePath              = pArgs.cFilePath
    ket                    = pArgs.ket
    optLevel               = pArgs.optLevel
    cFileMetaDir           = cFilePath.with_suffix('.d')
    genBinPath             = cFileMetaDir / f'{cFilePath.stem}_{ket}_{optLevel}'
    ''' Runs valgrind-memcheck, cfgg-asmmap, valgrind-cfgg and cfgg-info '''

    res, err = CFGgrind(genBinPath, pArgs.fnName).runcmd()

    return (pArgs if err != failure
            else pArgs.Err(f'CFGgrind:\n{res}\n'))


def _start(self: Application, ) -> SysExitCode:

    # For each directory passed with -i/--inputdir, do:
    for benchDir in self.inputBenchmarks:

        pArgs = [BenchInfo(cf) for cf in benchDir.glob('*.c')]

        # [-c] Deletes 
        if self.args.clean:
            with Pool(self.nproc) as pool:
                pool.map(_cleanFn, pArgs, len(pArgs) // self.nproc // 2 + 1)
                pool.close()
                pool.join()
            return success


        with Pool(self.nproc, maxtasksperchild=self.mtpc) as pool:

            # benchDir/descriptor <- PrintDescriptors
            resGenDesc = [r for r in pool.map(_genDescriptor, pArgs, self.chunksize) if valid(r)]
            if not resGenDesc:
                return '[PrintDescriptors] No descriptors were generated'

            konsInput = [BenchInfo(bi.cFilePath, bi.fnName, ket=ket)
                         for bi in resGenDesc for ket in self.ketList]

            # benchDir/constraints <- Konstrain
            resKons = [r for r in pool.map(_runKonstrain, konsInput, self.chunksize) if valid(r)]
            if not resKons:
                return '[Konstrain] No constraints were generated'

            # benchDir/genBench.c <- Jotai
            resJotai = [r for r in pool.map(_runJotai, resKons, self.chunksize) if valid(r)]
            if not resJotai:
                return '[Jotai] No benchmarks with entry points were generated'

            clangInput = [BenchInfo(bi.cFilePath, bi.fnName, bi.ket, optLevel)
                          for bi in resJotai for optLevel in self.optLevels]

            # benchDir/genBench <- clang
            resClang = [r for r in pool.map(_compileGenBench, clangInput, self.chunksize) if valid(r)]

            if not resClang:
                return '[Clang] No benchmarks with entry points compiled successfully'

            resValgrind = [r for r in pool.map(_runCFGgrind, resClang, self.chunksize)]
            if not resValgrind:
                return '[Valgrind/CFGgrind] No binary executed successfully'

            pool.close()
            pool.join()

        # TODO: Refine this
        ubCounter = {}
        ubCounter = Counter([(e.optLevel, e.exitCode) for e in resValgrind])
        try:
            with open(self.ubstats, 'w+') as ofhandle:
                ofhandle.write('Undefined behavior count:\n')
                ofhandle.writelines([f'{v, c}' for v, c in ubCounter.items()])
                ofhandle.write('\n')
        except Exception as e: logging.error(f'{e}')

    return success


def main() -> SysExitCode:
    return Application().start()



# =========================================================================== #
